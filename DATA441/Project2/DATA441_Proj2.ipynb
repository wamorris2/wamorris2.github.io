{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 2: Alex Gramfort's Locally Weighted Regression\n",
        "### Willem Morris"
      ],
      "metadata": {
        "id": "KhCgTElC0tJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZf9scL_ayht",
        "outputId": "355a3602-14d5-4a74-f0b0-d3b5aa378a64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jWwdn6dWaBUS"
      },
      "outputs": [],
      "source": [
        "# graphical libraries\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 120\n",
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "plt.style.use('seaborn-white')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# computational libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.spatial import Delaunay\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "import scipy.stats as stats \n",
        "from sklearn.model_selection import train_test_split as tts, KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from scipy.interpolate import interp1d, griddata, LinearNDInterpolator, NearestNDInterpolator\n",
        "from math import ceil\n",
        "from scipy import linalg\n",
        "# the following line(s) are necessary if you want to make SKlearn compliant functions\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
      ],
      "metadata": {
        "id": "wEkJ-bHpaFAy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = LinearRegression()\n",
        "scale = StandardScaler()\n",
        "qscale = QuantileTransformer()"
      ],
      "metadata": {
        "id": "ZnbnKZY7au3p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist(u,v):\n",
        "  if len(v.shape)==1:\n",
        "    v = v.reshape(1,-1) # if v only has one observation, make it a row vector\n",
        "  d = np.array([np.sqrt(np.sum((u-v[i])**2,axis=1)) for i in range(len(v))])\n",
        "  return d"
      ],
      "metadata": {
        "id": "YT-YeQIKbIfO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lowessag_md(xtrain, ytrain, xtest, f=2/3, iter=3, intercept=True):\n",
        "  n = len(xtrain)\n",
        "  r = int(ceil(f * n))\n",
        "  yest = np.zeros(n)\n",
        "\n",
        "  # here we make column vectors\n",
        "  ytrain = ytrain.reshape(-1,1) if len(ytrain.shape)==1 else ytrain\n",
        "  xtrain = xtrain.reshape(-1,1) if len(xtrain.shape)==1 else xtrain\n",
        "  \n",
        "  x1 = np.column_stack([np.ones((n,1)),xtrain]) if intercept else xtrain\n",
        "\n",
        "  h = [np.sort(np.sqrt(np.sum((xtrain-xtrain[i])**2,axis=1)))[r] for i in range(n)]\n",
        "\n",
        "  w = np.clip(dist(xtrain,xtrain) / h, 0.0, 1.0)\n",
        "  w = (1 - w ** 3) ** 3\n",
        "\n",
        "  #Looping through all X-points\n",
        "  delta = np.ones(n)\n",
        "  for iteration in range(iter):\n",
        "    for i in range(n):\n",
        "      W = np.diag(w[:,i])\n",
        "      b = np.transpose(x1).dot(W).dot(ytrain)\n",
        "      A = np.transpose(x1).dot(W).dot(x1)\n",
        "      A = A + 0.0001*np.eye(x1.shape[1]) # if we want L2 regularization\n",
        "      beta = linalg.solve(A, b)\n",
        "      #beta, res, rnk, s = linalg.lstsq(A, b)\n",
        "      yest[i] = np.dot(x1[i],beta)\n",
        "\n",
        "    residuals = ytrain - yest\n",
        "    s = np.median(np.abs(residuals))\n",
        "    delta = np.clip(residuals / (6.0 * s), -1, 1)\n",
        "    delta = (1 - delta ** 2) ** 2\n",
        "\n",
        "  if x.shape[1]==1:\n",
        "    f = interp1d(xtrain.flatten(),yest,fill_value='extrapolate')\n",
        "    output = f(xtest)\n",
        "  else:\n",
        "    output = np.zeros(len(xtest))\n",
        "    for i in range(len(xtest)):\n",
        "      ind = np.argsort(np.sqrt(np.sum((xtrain-xtest[i])**2,axis=1)))[:r]\n",
        "      # the following code lets the Delauny triangulation work\n",
        "      pca = PCA(n_components=3)\n",
        "      x_pca = pca.fit_transform(xtrain[ind])\n",
        "      tri = Delaunay(x_pca,qhull_options='QJ')\n",
        "      f = LinearNDInterpolator(tri,ytrain[ind])\n",
        "      output[i] = f(pca.transform(xtest[i].reshape(1,-1))) # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
        "  if sum(np.isnan(output))>0:\n",
        "    g = NearestNDInterpolator(xtrain,ytrain.ravel()) \n",
        "    output[np.isnan(output)] = g(xtest[np.isnan(output)])\n",
        "  return output"
      ],
      "metadata": {
        "id": "gXTw2GvMa9K8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kfold_lw(x, y, n_splits=10, random_state=1234):\n",
        "  mse_lw = []\n",
        "  scale = StandardScaler()\n",
        "  kf = KFold(n_splits=n_splits, shuffle=True, random_state=1234)\n",
        "\n",
        "  for idxtrain, idxtest in kf.split(x):\n",
        "    xtrain = scale.fit_transform(x[idxtrain])\n",
        "    ytrain = y[idxtrain]\n",
        "    xtest  = scale.transform(x[idxtest])\n",
        "    ytest  = y[idxtest]\n",
        "\n",
        "    yest = lowessag_md(xtrain, ytrain, xtest)\n",
        "\n",
        "    mse_lw.append(mse(ytest, yest))\n",
        "  \n",
        "  return np.mean(mse_lw)"
      ],
      "metadata": {
        "id": "LnioU9jMp9Wd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('drive/MyDrive/Data Sets/cars.csv')\n",
        "x = data.loc[:,'CYL':'WGT'].values\n",
        "y = data['MPG'].values\n",
        "print('The Cross-validated Mean Squared Error for the car data is : '+str(kfold_lw(x,y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtzdBs2tmB7Q",
        "outputId": "7aa0c0e8-3b62-47a9-bba6-15f4b05484de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Cross-validated Mean Squared Error for the car data is : 21.572708675835393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('drive/MyDrive/Data Sets/concrete.csv')\n",
        "x = data.loc[:,'cement':'age'].values\n",
        "y = data['strength'].values\n",
        "print('The cross-validated mean squared error for the concrete data is : '+str(kfold_lw(x,y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxkKC2pArh7d",
        "outputId": "37fbf3c2-44f9-41b0-ab49-4fe43699eaf5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cross-validated mean squared error for the concrete data is : 70.38214530730352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Lowess_AG_MD:\n",
        "    def __init__(self, f = 1/10, iter = 3,intercept=True):\n",
        "        self.f = f\n",
        "        self.iter = iter\n",
        "        self.intercept = intercept\n",
        "    \n",
        "    def fit(self, x, y):\n",
        "        f = self.f\n",
        "        iter = self.iter\n",
        "        self.xtrain_ = x\n",
        "        self.yhat_ = y\n",
        "\n",
        "    def predict(self, xnew):\n",
        "        check_is_fitted(self)\n",
        "        x = self.xtrain_\n",
        "        y = self.yhat_\n",
        "        f = self.f\n",
        "        iter = self.iter\n",
        "        intercept = self.intercept\n",
        "        return lowessag_md(x, y, xnew, f, iter, intercept)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "    # suppose this estimator has parameters \"f\", \"iter\" and \"intercept\"\n",
        "        return {\"f\": self.f, \"iter\": self.iter,\"intercept\":self.intercept}\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        return self"
      ],
      "metadata": {
        "id": "ktksXZkmr6sP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scale = StandardScaler()\n",
        "lwr_pipe = Pipeline([('zscores', StandardScaler()),\n",
        "                     ('lwr', Lowess_AG_MD())])\n",
        "params = [{'lwr__f': [1/i for i in range(3,15)],\n",
        "         'lwr__iter': [1,2,3,4]}]\n",
        "gs_lowess = GridSearchCV(lwr_pipe,\n",
        "                      param_grid=params,\n",
        "                      scoring='neg_mean_squared_error',\n",
        "                      cv=5)\n",
        "gs_lowess.fit(scale.fit_transform(x), y)\n",
        "gs_lowess.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3vc7gzUzCEt",
        "outputId": "6e848581-ac96-41bd-ef00-fe8201288889"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lwr__f': 0.3333333333333333, 'lwr__iter': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_lowess.score(scale.fit_transform(x),y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecrsr9Uq0Xbl",
        "outputId": "95d139bb-7dcc-4e4d-b66b-7dab25fa9959"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.6547449275510313"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}